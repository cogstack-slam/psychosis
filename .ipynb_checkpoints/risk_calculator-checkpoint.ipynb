{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch_dsl import Search\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from datetime import date, datetime\n",
    "import logging\n",
    "from elastic_util import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from Cogstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('psychosis_risk_cal')\n",
    "handler = logging.StreamHandler()\n",
    "formatter = logging.Formatter(\n",
    "        '%(asctime)s %(name)-12s %(levelname)-8s : %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_elas_index(client, index, doc_type='doc'):\n",
    "    while not client.indices.exists(index):\n",
    "        time.sleep(30)\n",
    "    s = Search(using=client, index=index, doc_type=doc_type).filter('match', coeff_validated='0')\n",
    "    logger.info('Loaded %s documents' %s.count())\n",
    "    df = pd.DataFrame((d.to_dict() for d in s.scan()))\n",
    "    logger.info('Documents shape: %s %s' %(df.shape))\n",
    "    \n",
    "    logger.info('Change data types')\n",
    "    df['first_primary_diagnosis_date'] = pd.to_datetime(df['first_primary_diagnosis_date'])\n",
    "    df['patient_date_of_birth'] = pd.to_datetime(df['patient_date_of_birth'])\n",
    "    df['first_primary_diagnosis_recorded_date'] = pd.to_datetime(df['first_primary_diagnosis_recorded_date'])\n",
    "#     print(df.dtypes)\n",
    "#     df['patient_id'] = df['patient_id'].astype(int)\n",
    "#     df['referral_id'] = df['referral_id'].astype(int)\n",
    "    logger.info('Documents shape after changing data types: %s %s' %(df.shape))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethnicity (changed to lower for string match and added two mapping rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Added the following two lines in original list\n",
    "# Scottish (CB) --- British (A) \n",
    "# African --- African (N)\n",
    "def read_eth_mapping(file_path='ethnicity_mapping.txt'):\n",
    "    eth_map = {}\n",
    "    with open(file_path, 'r') as fr:\n",
    "        for line in fr.readlines():\n",
    "            tokens = line.strip().split('---')\n",
    "            eth_map[tokens[0].strip().lower()] = tokens[1].strip().lower()\n",
    "    return eth_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ethnicity_coeff(df):\n",
    "    eth_map = read_eth_mapping()\n",
    "    logger.info('Mapping ePJS ethnicity names to CRIS ethnicity names')\n",
    "    df['patient_demography_ethnicity_cris'] = df['patient_demography_ethnicity'].str.lower()\n",
    "    df['patient_demography_ethnicity_cris'] = df['patient_demography_ethnicity_cris'].map(eth_map)\n",
    "#     print(set(df['patient_demography_ethnicity_cris']))\n",
    "    \n",
    "    logger.info('Calcuating ethnicity coeffs')\n",
    "    df['eth_coeff'] = None\n",
    "    black = [s.lower() for s in ['Caribbean (M)','African (N)','Any other black background (P)']]\n",
    "    white = [s.lower() for s in ['British (A)','Irish (B)','Any other white background (C)']]\n",
    "    asian = [s.lower() for s in ['Indian (H)','Pakistani (J)','Any other Asian background (L)','Chinese (R)','Bangladeshi (K)']]\n",
    "    mixed = [s.lower() for s in ['White and black Caribbean (D)','White and Black African (E)','White and Asian (F)','Any other mixed background (G)']]\n",
    "    other = [s.lower() for s in ['Any other ethnic group (S)']]\n",
    "\n",
    "    df.loc[df['patient_demography_ethnicity_cris'].isin(asian), 'eth_coeff'] = 0.5143438\n",
    "    df.loc[df['patient_demography_ethnicity_cris'].isin(black), 'eth_coeff'] = 1.037915\n",
    "    df.loc[df['patient_demography_ethnicity_cris'].isin(mixed), 'eth_coeff'] = 0.6044039\n",
    "    df.loc[df['patient_demography_ethnicity_cris'].isin(other), 'eth_coeff'] = 0.4081036\n",
    "    df.loc[df['patient_demography_ethnicity_cris'].isin(white), 'eth_coeff'] = 0.0\n",
    "    df['eth_coeff'] = df['eth_coeff'].astype(float)\n",
    "    \n",
    "    # CRIS ethnicity categories that are not mapped in the code\n",
    "#     print(set(df['patient_demography_ethnicity_cris']) - set(black) - set(white) - set(asian) - set(mixed) - set(other))\n",
    "    logger.info('Finished calcuating ethnicity coeffs')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_coeff(df):\n",
    "    logger.info('Calcuating gender coeffs')\n",
    "    df['gender_coeff'] = None\n",
    "    df.loc[df['patient_demography_gender']=='Female', 'gender_coeff'] = 0.0 \n",
    "    df.loc[df['patient_demography_gender']=='Male', 'gender_coeff'] = 0.5681779    \n",
    "    df['gender_coeff'] = df['gender_coeff'].astype(float)\n",
    "    logger.info('Finished calcuating gender coeffs')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.floor(13.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age should be int, not float. using floor. \n",
    "def age_coeff(df):\n",
    "    logger.info('Calcuating age coeffs')\n",
    "    df['age_coeff'] = None\n",
    "\n",
    "    df['age_at_index_diagnosis'] = np.floor((df['first_primary_diagnosis_date'] - df['patient_date_of_birth'])/np.timedelta64(1, 'Y'))\n",
    "    df['age_coeff'] = df['age_at_index_diagnosis']*0.0117113\n",
    "    df['age_coeff'] = df['age_coeff'].astype(float)\n",
    "    logger.info('Finished calcuating age coeffs')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender & Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_age_coeff(df):\n",
    "    logger.info('Calcuating gender*age coeffs')\n",
    "    df['gender_age_coeff'] = None\n",
    "    df.loc[df['patient_demography_gender']=='Female', 'gender_age_coeff'] = 0.0\n",
    "    df.loc[df['patient_demography_gender']=='Male', 'gender_age_coeff'] = 0.0121931*df['age_at_index_diagnosis']\n",
    "    df['gender_age_coeff'] = df['gender_age_coeff'].astype(float)\n",
    "    logger.info('Finished calcuating gender*age coeffs')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diagnosis index (added exclusions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diag_coeff(df):\n",
    "    # Diagnosis mapping\n",
    "    \n",
    "    Psychotic = tuple(['F20', 'F25.0', 'F25.1', 'F25.2', 'F25.8', 'F25.9', 'F22.0', 'F22.8', 'F22.9', 'F24', 'F28', 'F29',\n",
    "                      'F30.2', 'F31.2', 'F31.5', 'F32.3', 'F33.3', 'F53.1'] + \n",
    "                     ['F1'+ str(i) + '.' + str(j) for i in range(10) for j in [4, 5, 7]])\n",
    "    Psychotic_exclude = tuple(['F20.7'])\n",
    "    \n",
    "    Acute = tuple(['F23'])\n",
    "\n",
    "    Substance = tuple(['F1'])\n",
    "    Substance_exclude = tuple(['F1'+ str(i) + '.' + str(j) for i in range(10) for j in [4, 5, 7]])\n",
    "\n",
    "    Bipolar = tuple(['F31', 'F34.0', 'F30'])\n",
    "    Bipolar_exclude = tuple(['F31.2', 'F31.5', 'F30.2'])\n",
    "\n",
    "    Non_bipolar = tuple(['F32', 'F33', 'F34.1', 'F34.8', 'F34.9', 'F38', 'F39'])\n",
    "    Non_bipolar_exclude = tuple(['F32.3', 'F33.3'])\n",
    "\n",
    "    Anxiety = tuple(['F40', 'F41', 'F42', 'F43', 'F44', 'F45', 'F48'])\n",
    "\n",
    "    Personality = tuple(['F60', 'F61', 'F62', 'F68', 'F69', 'F21', 'F63', 'F64', 'F65', 'F66'])\n",
    "\n",
    "    Developmental = tuple(['F80', 'F81', 'F82', 'F83', 'F84', 'F88', 'F89'])\n",
    "\n",
    "    Childhood = tuple(['F90', 'F91', 'F92', 'F93', 'F94', 'F98', 'F95'])\n",
    "\n",
    "    Physiological = tuple(['F50', 'F51', 'F52', 'F53', 'F54', 'F55', 'F59'])\n",
    "    Physiological_exclude = tuple(['F53.1'])\n",
    "\n",
    "    Mental = tuple(['F70', 'F71', 'F72', 'F73', 'F78', 'F79'])\n",
    "    \n",
    "    Organic = tuple(['F0'])\n",
    "    \n",
    "    logger.info('Mapping ICD-10 codes to disorder categories')\n",
    "    df['diagnosis_group'] = None\n",
    "# \n",
    "    df.loc[df['first_primary_diagnosis'].notna(), 'diagnosis_group'] = 'Other' # All other diagnoses not in list of interest\n",
    "    df.loc[df['first_primary_diagnosis'].str.startswith(Psychotic) & (~df['first_primary_diagnosis'].str.startswith(Psychotic_exclude)), 'diagnosis_group'] = 'Psychotic disorder'\n",
    "    df.loc[df['first_primary_diagnosis'].str.startswith(Acute), 'diagnosis_group'] = 'Acute and transient psychotic disorders'\n",
    "    df.loc[df['first_primary_diagnosis'].str.startswith(Substance) & (~df['first_primary_diagnosis'].str.startswith(Substance_exclude)), 'diagnosis_group'] = 'Substance use disorders'\n",
    "    df.loc[df['first_primary_diagnosis'].str.startswith(Bipolar) & (~df['first_primary_diagnosis'].str.startswith(Bipolar_exclude)), 'diagnosis_group'] = 'Bipolar mood disorders'\n",
    "    df.loc[df['first_primary_diagnosis'].str.startswith(Non_bipolar) & (~df['first_primary_diagnosis'].str.startswith(Non_bipolar_exclude)), 'diagnosis_group'] = 'Non bipolar mood disorders'\n",
    "    df.loc[df['first_primary_diagnosis'].str.startswith(Anxiety), 'diagnosis_group'] = 'Anxiety disorders'\n",
    "    df.loc[df['first_primary_diagnosis'].str.startswith(Personality), 'diagnosis_group'] = 'Personality disorders'\n",
    "    df.loc[df['first_primary_diagnosis'].str.startswith(Developmental), 'diagnosis_group'] = 'Developmental disorders'\n",
    "    df.loc[df['first_primary_diagnosis'].str.startswith(Childhood), 'diagnosis_group'] = 'Childhood/adolescence onset disorders'\n",
    "    df.loc[df['first_primary_diagnosis'].str.startswith(Physiological) & (~df['first_primary_diagnosis'].str.startswith(Physiological_exclude)), 'diagnosis_group'] = 'Physiological syndromes'\n",
    "    df.loc[df['first_primary_diagnosis'].str.startswith(Mental), 'diagnosis_group'] = 'Mental retardation'\n",
    "    df.loc[df['first_primary_diagnosis'].str.startswith(Organic), 'diagnosis_group'] = 'Organic mental disorder'\n",
    "    logger.info('Finshed mapping ICD-10 codes to disorder categories')\n",
    "    \n",
    "    logger.info('Calculating diagnosis coeffs')\n",
    "    df['diagnosis_group_coeff'] = None\n",
    "#     df.loc[df['diagnosis_group'] == 'Psychotic disorder', 'diagnosis_group_coeff'] = 0.0 # Comment this for excluding 'Psychotic disorder'\n",
    "    df.loc[df['diagnosis_group'] == 'Acute and transient psychotic disorders', 'diagnosis_group_coeff'] = 0.9867204\n",
    "    df.loc[df['diagnosis_group'] == 'Substance use disorders', 'diagnosis_group_coeff'] = -1.925903\n",
    "    df.loc[df['diagnosis_group'] == 'Bipolar mood disorders', 'diagnosis_group_coeff'] = -0.1754082\n",
    "    df.loc[df['diagnosis_group'] == 'Non bipolar mood disorders', 'diagnosis_group_coeff'] = -1.886428\n",
    "    df.loc[df['diagnosis_group'] == 'Anxiety disorders', 'diagnosis_group_coeff'] = -2.235825\n",
    "    df.loc[df['diagnosis_group'] == 'Personality disorders', 'diagnosis_group_coeff'] = -1.547794\n",
    "    df.loc[df['diagnosis_group'] == 'Developmental disorders', 'diagnosis_group_coeff'] = -3.466732\n",
    "    df.loc[df['diagnosis_group'] == 'Childhood/adolescence onset disorders', 'diagnosis_group_coeff'] = -3.25382\n",
    "    df.loc[df['diagnosis_group'] == 'Physiological syndromes', 'diagnosis_group_coeff'] = -2.463145\n",
    "    df.loc[df['diagnosis_group'] == 'Mental retardation', 'diagnosis_group_coeff'] = -2.450679\n",
    "    \n",
    "    df['diagnosis_group_coeff'] = df['diagnosis_group_coeff'].astype(float)\n",
    "    logger.info('Finished calculating diagnosis coeffs')\n",
    "    \n",
    "    \n",
    "    logger.info('Labeling records that do not miss any predictors')\n",
    "#     df['coeff_validated'] = False\n",
    "    df.loc[df['diagnosis_group'].notna() & df['age_coeff'].notna()\n",
    "           & df['eth_coeff'].notna() & df['gender_coeff'].notna(), 'coeff_validated'] = '1'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk_score(df):\n",
    "    logger.info('Calculating risk scores per year')\n",
    "    \n",
    "    df['PI'] = None\n",
    "    df.loc[df['diagnosis_group_coeff'].notna() & df['age_coeff'].notna()\n",
    "           & df['eth_coeff'].notna() & df['gender_coeff'].notna(), 'PI'] = df['gender_coeff'] + df['age_coeff'] - df['gender_age_coeff'] + df['eth_coeff'] + df['diagnosis_group_coeff']\n",
    "    df['risk_calculated_dttm'] = datetime.now()\n",
    "#     dfvald = df.loc[df['coeff_validated'] == True] # Records that with \"coeff_validated == True\" can hava diagnoses in 'Psychotic disorder','Organic mental disorder' and others. Risk scores of these records are not calculated\n",
    "    \n",
    "    df.loc[df['PI'].notna(), 'exist_risk_score'] = '1'\n",
    "    \n",
    "    dfpi = df.loc[df['exist_risk_score'] == '1']\n",
    "    dfpi = dfpi.copy()\n",
    "    dfpi['PI'] = dfpi['PI'].astype(float)\n",
    "    \n",
    "    # https://data.princeton.edu/wws509/notes/c7.pdf Eq. 7.11  \n",
    "    pi_exp = np.exp(dfpi['PI'].astype(float))\n",
    "    dfpi.loc[dfpi['PI'].notna(),'h_1_year'] = 1 - (0.9714991 ** pi_exp)\n",
    "    dfpi.loc[dfpi['PI'].notna(),'h_2_year'] = 1 - (0.9540228 ** pi_exp)\n",
    "    dfpi.loc[dfpi['PI'].notna(),'h_3_year'] = 1 - (0.9403899 ** pi_exp)\n",
    "    dfpi.loc[dfpi['PI'].notna(),'h_4_year'] = 1 - (0.9273409 ** pi_exp)\n",
    "    dfpi.loc[dfpi['PI'].notna(),'h_5_year'] = 1 - (0.9160071 ** pi_exp)\n",
    "    dfpi.loc[dfpi['PI'].notna(),'h_6_year'] = 1 - (0.9086922 ** pi_exp)\n",
    "    \n",
    "    \n",
    "    logger.info('Finished calculating risk scores per year')\n",
    "    return df, dfpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-13 14:16:21,702 psychosis_risk_cal INFO     : Connect to host.....\n",
      "2019-05-13 14:16:21,702 psychosis_risk_cal INFO     : Connect to host.....\n",
      "2019-05-13 14:16:21,702 psychosis_risk_cal INFO     : Connect to host.....\n",
      "2019-05-13 14:16:21,702 psychosis_risk_cal INFO     : Connect to host.....\n",
      "2019-05-13 14:16:21,717 psychosis_risk_cal INFO     : Loaded 163260 documents\n",
      "2019-05-13 14:16:21,717 psychosis_risk_cal INFO     : Loaded 163260 documents\n",
      "2019-05-13 14:16:21,717 psychosis_risk_cal INFO     : Loaded 163260 documents\n",
      "2019-05-13 14:16:21,717 psychosis_risk_cal INFO     : Loaded 163260 documents\n",
      "2019-05-13 14:16:32,181 psychosis_risk_cal INFO     : Documents shape: 163253 17\n",
      "2019-05-13 14:16:32,181 psychosis_risk_cal INFO     : Documents shape: 163253 17\n",
      "2019-05-13 14:16:32,181 psychosis_risk_cal INFO     : Documents shape: 163253 17\n",
      "2019-05-13 14:16:32,181 psychosis_risk_cal INFO     : Documents shape: 163253 17\n",
      "2019-05-13 14:16:32,186 psychosis_risk_cal INFO     : Change data types\n",
      "2019-05-13 14:16:32,186 psychosis_risk_cal INFO     : Change data types\n",
      "2019-05-13 14:16:32,186 psychosis_risk_cal INFO     : Change data types\n",
      "2019-05-13 14:16:32,186 psychosis_risk_cal INFO     : Change data types\n",
      "2019-05-13 14:16:33,165 psychosis_risk_cal INFO     : Documents shape after changing data types: 163253 17\n",
      "2019-05-13 14:16:33,165 psychosis_risk_cal INFO     : Documents shape after changing data types: 163253 17\n",
      "2019-05-13 14:16:33,165 psychosis_risk_cal INFO     : Documents shape after changing data types: 163253 17\n",
      "2019-05-13 14:16:33,165 psychosis_risk_cal INFO     : Documents shape after changing data types: 163253 17\n",
      "2019-05-13 14:16:33,253 psychosis_risk_cal INFO     : Mapping ePJS ethnicity names to CRIS ethnicity names\n",
      "2019-05-13 14:16:33,253 psychosis_risk_cal INFO     : Mapping ePJS ethnicity names to CRIS ethnicity names\n",
      "2019-05-13 14:16:33,253 psychosis_risk_cal INFO     : Mapping ePJS ethnicity names to CRIS ethnicity names\n",
      "2019-05-13 14:16:33,253 psychosis_risk_cal INFO     : Mapping ePJS ethnicity names to CRIS ethnicity names\n",
      "2019-05-13 14:16:33,492 psychosis_risk_cal INFO     : Calcuating ethnicity coeffs\n",
      "2019-05-13 14:16:33,492 psychosis_risk_cal INFO     : Calcuating ethnicity coeffs\n",
      "2019-05-13 14:16:33,492 psychosis_risk_cal INFO     : Calcuating ethnicity coeffs\n",
      "2019-05-13 14:16:33,492 psychosis_risk_cal INFO     : Calcuating ethnicity coeffs\n",
      "2019-05-13 14:16:34,353 psychosis_risk_cal INFO     : Finished calcuating ethnicity coeffs\n",
      "2019-05-13 14:16:34,353 psychosis_risk_cal INFO     : Finished calcuating ethnicity coeffs\n",
      "2019-05-13 14:16:34,353 psychosis_risk_cal INFO     : Finished calcuating ethnicity coeffs\n",
      "2019-05-13 14:16:34,353 psychosis_risk_cal INFO     : Finished calcuating ethnicity coeffs\n",
      "2019-05-13 14:16:34,357 psychosis_risk_cal INFO     : Calcuating gender coeffs\n",
      "2019-05-13 14:16:34,357 psychosis_risk_cal INFO     : Calcuating gender coeffs\n",
      "2019-05-13 14:16:34,357 psychosis_risk_cal INFO     : Calcuating gender coeffs\n",
      "2019-05-13 14:16:34,357 psychosis_risk_cal INFO     : Calcuating gender coeffs\n",
      "2019-05-13 14:16:35,186 psychosis_risk_cal INFO     : Finished calcuating gender coeffs\n",
      "2019-05-13 14:16:35,186 psychosis_risk_cal INFO     : Finished calcuating gender coeffs\n",
      "2019-05-13 14:16:35,186 psychosis_risk_cal INFO     : Finished calcuating gender coeffs\n",
      "2019-05-13 14:16:35,186 psychosis_risk_cal INFO     : Finished calcuating gender coeffs\n",
      "2019-05-13 14:16:35,190 psychosis_risk_cal INFO     : Calcuating age coeffs\n",
      "2019-05-13 14:16:35,190 psychosis_risk_cal INFO     : Calcuating age coeffs\n",
      "2019-05-13 14:16:35,190 psychosis_risk_cal INFO     : Calcuating age coeffs\n",
      "2019-05-13 14:16:35,190 psychosis_risk_cal INFO     : Calcuating age coeffs\n",
      "2019-05-13 14:16:35,218 psychosis_risk_cal INFO     : Finished calcuating age coeffs\n",
      "2019-05-13 14:16:35,218 psychosis_risk_cal INFO     : Finished calcuating age coeffs\n",
      "2019-05-13 14:16:35,218 psychosis_risk_cal INFO     : Finished calcuating age coeffs\n",
      "2019-05-13 14:16:35,218 psychosis_risk_cal INFO     : Finished calcuating age coeffs\n",
      "2019-05-13 14:16:35,222 psychosis_risk_cal INFO     : Calcuating gender*age coeffs\n",
      "2019-05-13 14:16:35,222 psychosis_risk_cal INFO     : Calcuating gender*age coeffs\n",
      "2019-05-13 14:16:35,222 psychosis_risk_cal INFO     : Calcuating gender*age coeffs\n",
      "2019-05-13 14:16:35,222 psychosis_risk_cal INFO     : Calcuating gender*age coeffs\n",
      "2019-05-13 14:16:36,151 psychosis_risk_cal INFO     : Finished calcuating gender*age coeffs\n",
      "2019-05-13 14:16:36,151 psychosis_risk_cal INFO     : Finished calcuating gender*age coeffs\n",
      "2019-05-13 14:16:36,151 psychosis_risk_cal INFO     : Finished calcuating gender*age coeffs\n",
      "2019-05-13 14:16:36,151 psychosis_risk_cal INFO     : Finished calcuating gender*age coeffs\n",
      "2019-05-13 14:16:36,155 psychosis_risk_cal INFO     : Mapping ICD-10 codes to disorder categories\n",
      "2019-05-13 14:16:36,155 psychosis_risk_cal INFO     : Mapping ICD-10 codes to disorder categories\n",
      "2019-05-13 14:16:36,155 psychosis_risk_cal INFO     : Mapping ICD-10 codes to disorder categories\n",
      "2019-05-13 14:16:36,155 psychosis_risk_cal INFO     : Mapping ICD-10 codes to disorder categories\n",
      "2019-05-13 14:16:37,991 psychosis_risk_cal INFO     : Finshed mapping ICD-10 codes to disorder categories\n",
      "2019-05-13 14:16:37,991 psychosis_risk_cal INFO     : Finshed mapping ICD-10 codes to disorder categories\n",
      "2019-05-13 14:16:37,991 psychosis_risk_cal INFO     : Finshed mapping ICD-10 codes to disorder categories\n",
      "2019-05-13 14:16:37,991 psychosis_risk_cal INFO     : Finshed mapping ICD-10 codes to disorder categories\n",
      "2019-05-13 14:16:37,995 psychosis_risk_cal INFO     : Calculating diagnosis coeffs\n",
      "2019-05-13 14:16:37,995 psychosis_risk_cal INFO     : Calculating diagnosis coeffs\n",
      "2019-05-13 14:16:37,995 psychosis_risk_cal INFO     : Calculating diagnosis coeffs\n",
      "2019-05-13 14:16:37,995 psychosis_risk_cal INFO     : Calculating diagnosis coeffs\n",
      "2019-05-13 14:16:39,146 psychosis_risk_cal INFO     : Finished calculating diagnosis coeffs\n",
      "2019-05-13 14:16:39,146 psychosis_risk_cal INFO     : Finished calculating diagnosis coeffs\n",
      "2019-05-13 14:16:39,146 psychosis_risk_cal INFO     : Finished calculating diagnosis coeffs\n",
      "2019-05-13 14:16:39,146 psychosis_risk_cal INFO     : Finished calculating diagnosis coeffs\n",
      "2019-05-13 14:16:39,150 psychosis_risk_cal INFO     : Labeling records that do not miss any predictors\n",
      "2019-05-13 14:16:39,150 psychosis_risk_cal INFO     : Labeling records that do not miss any predictors\n",
      "2019-05-13 14:16:39,150 psychosis_risk_cal INFO     : Labeling records that do not miss any predictors\n",
      "2019-05-13 14:16:39,150 psychosis_risk_cal INFO     : Labeling records that do not miss any predictors\n",
      "2019-05-13 14:16:39,224 psychosis_risk_cal INFO     : Calculating risk scores per year\n",
      "2019-05-13 14:16:39,224 psychosis_risk_cal INFO     : Calculating risk scores per year\n",
      "2019-05-13 14:16:39,224 psychosis_risk_cal INFO     : Calculating risk scores per year\n",
      "2019-05-13 14:16:39,224 psychosis_risk_cal INFO     : Calculating risk scores per year\n",
      "2019-05-13 14:16:40,619 psychosis_risk_cal INFO     : Finished calculating risk scores per year\n",
      "2019-05-13 14:16:40,619 psychosis_risk_cal INFO     : Finished calculating risk scores per year\n",
      "2019-05-13 14:16:40,619 psychosis_risk_cal INFO     : Finished calculating risk scores per year\n",
      "2019-05-13 14:16:40,619 psychosis_risk_cal INFO     : Finished calculating risk scores per year\n",
      "2019-05-13 14:16:40,722 psychosis_risk_cal INFO     : Write patients at risk into Cogstack\n",
      "2019-05-13 14:16:40,722 psychosis_risk_cal INFO     : Write patients at risk into Cogstack\n",
      "2019-05-13 14:16:40,722 psychosis_risk_cal INFO     : Write patients at risk into Cogstack\n",
      "2019-05-13 14:16:40,722 psychosis_risk_cal INFO     : Write patients at risk into Cogstack\n",
      "2019-05-13 14:16:40,734 psychosis_risk_cal INFO     : Numbers of risky patients: 122545 32\n",
      "2019-05-13 14:16:40,734 psychosis_risk_cal INFO     : Numbers of risky patients: 122545 32\n",
      "2019-05-13 14:16:40,734 psychosis_risk_cal INFO     : Numbers of risky patients: 122545 32\n",
      "2019-05-13 14:16:40,734 psychosis_risk_cal INFO     : Numbers of risky patients: 122545 32\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 2.7, use buffering of HTTP responses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                 \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: getresponse() got an unexpected keyword argument 'buffering'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-8003bf0767c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mTYPE\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"doc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mdoc_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'patient_id'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbulk_insert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_risk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINDEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Write sucessfully!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/psychosis/elastic_util.py\u001b[0m in \u001b[0;36mbulk_insert\u001b[0;34m(client, df, INDEX, TYPE, doc_index)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbulk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec_to_actions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mINDEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# return a dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"errors\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elasticsearch/client/utils.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elasticsearch/client/__init__.py\u001b[0m in \u001b[0;36mbulk\u001b[0;34m(self, body, doc_type, index, params)\u001b[0m\n\u001b[1;32m   1442\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bulk_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1444\u001b[0;31m             \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"content-type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"application/x-ndjson\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1445\u001b[0m         )\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elasticsearch/transport.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, headers, params, body)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mdelay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mattempt\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                 \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTransportError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/elasticsearch/connection/http_urllib3.py\u001b[0m in \u001b[0;36mperform_request\u001b[0;34m(self, method, url, params, body, timeout, ignore, headers)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             response = self.pool.urlopen(\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRetry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest_headers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m             )\n\u001b[1;32m    222\u001b[0m             \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m                                                   chunked=chunked)\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m             \u001b[0;31m# If we're going to release the connection in ``finally:``, then\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Python 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                     \u001b[0mhttplib_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     \u001b[0;31m# Remove the TypeError from the exception chain in Python 3;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mgetresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1319\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m                 \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mbegin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;31m# read until we get a non-100 response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCONTINUE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36m_read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_MAXLINE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"iso-8859-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0m_MAXLINE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mLineTooLong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"status line\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    logger.info('Connect to host.....')\n",
    "    client = Elasticsearch(['http://10.16.31.65:9200/'], request_timeout=600)\n",
    "\n",
    "    df = read_elas_index(client, index='psychosis_base', doc_type='doc')\n",
    "    df = ethnicity_coeff(df)\n",
    "    df = gender_coeff(df)\n",
    "    df = age_coeff(df)\n",
    "    df = gender_age_coeff(df)\n",
    "    df = diag_coeff(df)\n",
    "    df, df_risk = risk_score(df)\n",
    "\n",
    "    logger.info('Write patients at risk into Cogstack')\n",
    "    logger.info('Numbers of risky patients: %s %s' %(df_risk.shape))\n",
    "    if df_risk.shape[0] > 0:\n",
    "        df_risk['alerted'] = False\n",
    "        df_risk['alerted_dttm'] = datetime.now()\n",
    "        INDEX=\"psychosis_risk\"\n",
    "        TYPE= \"doc\"\n",
    "        doc_index = 'patient_id'\n",
    "        res = bulk_insert(client, df_risk, INDEX, TYPE, doc_index)\n",
    "        if res:\n",
    "            logger.info('Write sucessfully!')\n",
    "        else:\n",
    "            logger.info('Write UNsucessfully!!!!')\n",
    "\n",
    "    logger.info('Update records in source table')\n",
    "    if df.shape[0] > 0:\n",
    "        INDEX=\"psychosis_base\"\n",
    "        TYPE= \"doc\"\n",
    "        doc_index = 'patient_id'\n",
    "        df_update = df[['patient_id','coeff_validated', 'risk_calculated_dttm', 'exist_risk_score']]\n",
    "        logger.info('Numbers of records that are needed to update: %s %s' %(df_update.shape))\n",
    "        res = bulk_update(client, df_update, INDEX, TYPE, doc_index)\n",
    "        if res:\n",
    "            logger.info('Updated sucessfully!')\n",
    "        else:\n",
    "            logger.info('Updated UNsucessfully!!!!')\n",
    "    time.sleep(12 * 60 * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
